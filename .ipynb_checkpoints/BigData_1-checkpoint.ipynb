{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop is general term for two units, Storage and Processing. Storage component is HDFS and Processing component is Yarn.\n",
    "\n",
    "HDFS allows you to dump any kind of data across the cluster. Yarn allows parallel processing on the data. It is data intensive,  because code is transferred to the data location.\n",
    "\n",
    "MapReduce: Map for parallel processing and Reduce for aggregation.\n",
    "\n",
    "Pig has two parts, pig latin - language and Pig runtime - Execution engine.\n",
    "\n",
    "Whenever you write pig script there will be MapReduce job running in the background.\n",
    "\n",
    "Hive - Powerful Analytical tool, uses HiveQL.\n",
    "\n",
    "Spark - very popular for real-time data processing. Written in scala. Executes In-memory computations. 100 times faster than MapReduce.\n",
    "\n",
    "Oozie - Schedules hadoop jobs.\n",
    "\n",
    "Flume - Ingestion tools for unstructured data.\n",
    "\n",
    "Sqoop - Ingestion tool for Strutured data.\n",
    "\n",
    "HDFS - Hadoop Distributed File System. HDFS has NameNode and DataNode.\n",
    "\n",
    "NameNode - Master Daemon. Maintains and manages data nodes. Stores meta data like location of blocks, size of the blocks, permissions, hierarchy and receives heart beat from data nodes.\n",
    "\n",
    "*Secondary NameNode:*\n",
    "\n",
    "Checkpointing is a process of capturing editlogs with Fslimage.\n",
    "\n",
    "Allows faster failover as we have backup of metadata.\n",
    "\n",
    "checkpoint happens periodically. Default once per hour.\n",
    "\n",
    "*FslImage:* File that contains state of the file system since the starting of the name node. Records meta data about all the transactions happened on the data eversince name node is set up.\n",
    "\n",
    "*EditLog* Recent modifications you made for the file systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hive is datawarehouse tool on top of HDFS. It creates tables on top of HDFS. You use hive when you are dealing with structured data and you want to avoid heavy java code.\n",
    "\n",
    "Whatever you load into HDFS they will be stored in the form of flat files. \n",
    "\n",
    "HDFS is schema on Read. RDBMS is schema on write. In RDBMS you need to specify the schema before storing the data. When it comes to HDFS you store the data in the form of Flat files. HDFS doesnt maintain any schema.\n",
    "\n",
    "Hive was created by facebook in 2008, and donated to Apache foundation. \n",
    "\n",
    "Metastore is RDBMS maintained by Hive. Metastore is created on top of HDFS files to give the structure to flat files stored in HDFS. \n",
    "\n",
    "When can create tables on top of HDFS files, you are giving structure to HDFS files by hive, to maintain structure information we use metastore.\n",
    "\n",
    "Whatever the query you are writing in the hive, it is internally converts into MapReduce and runs on Hadoop. \n",
    "\n",
    "Metastore is central repository of the hive metadata. Hive tables, database definitions and mapping to data in HDFS is stored in metastore.\n",
    "\n",
    "Hive metastore can be configured in 3 ways. 1)embedded metastore, 2)local metastore, 3)remote metastore.\n",
    "\n",
    "\n",
    "**Uses of Hive**\n",
    "\n",
    "Hive provides tools to Extract Transform and Load (ETL)\n",
    "\n",
    "Provides structure on variety of data formats.\n",
    "\n",
    "Used for OLAP.\n",
    "\n",
    "By using hive we can access files stored in HBase and HDFS.\n",
    "\n",
    "\n",
    "**Limitations of Hive**\n",
    "\n",
    "It is not a relational database. It is not OLTP. It is not a procedural language. It doesnt have triggers, stored procedures etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tez vs MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pig/Hive jobs can be written in SQL and they are converted to MapReduce jobs and run on top of the HDFS.\n",
    "\n",
    "Tez takes place of MapReduce, Instead of translating your queries into mappers and reducers, it translates it into Directed Acyclic Graphs (DAG). It is same idea that spark uses to run faster.\n",
    "\n",
    "Tez is default on EMR. But you can set configuration to MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot stop the clusters in EMR like EC2. \n",
    "\n",
    "In EMR you can select what software you want like Spark, Hive, Hue etc., and EMR configures all the software automatically for you. You just specify how many no. of instances you need.\n",
    "\n",
    "Whereas in EC2 you need to install and configure all your softwares, Name nodes and data nodes etc.,\n",
    "\n",
    "Terminated cluster metadata is stored for 2 days and you can clone it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
