{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Machine  - Can scale vertically\n",
    "\n",
    "**Distributed Machine**\n",
    "\n",
    "Horizontal Scaling,\n",
    "\n",
    "Commodity Hardware used in datanodes.\n",
    "\n",
    "Has access to computational resources across the number of machines connected through a network.\n",
    "\n",
    "Fault tolerance; if one of the machine fails, while network can still work.\n",
    "\n",
    "Replicating data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop is a way to distribute very large files across multiple machines.\n",
    "\n",
    "It has two components HDFS and MapReduce, HDFS which duplicates the data for fault tolerance. MapReduce allow computation on distributed data. \n",
    "\n",
    "128Mb default block size. default replication factor is 3.\n",
    "\n",
    "**MapReduce:** It is a way of splitting computational task to a distributed set of  files. It consists of *Job Tracker* and *Task Tracker*.\n",
    "\n",
    "**Job tracker** sends code to run on the task tracker.\n",
    "\n",
    "**Task Tracker** allocates CPU and memory to the tasks and monitor the tasks on the worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark vs MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative to MapReduce.\n",
    "\n",
    "MapReduce writes most of the data to disk after each map and reduce operation, spark keeps data in-memory after each transformatu=ion. Spark can spill over data to disk if the memory is filled.\n",
    "\n",
    "It can use data stored in variety of formats, and databases like Cassandra, S3, HDFS etc., Where as MapReduce can access data stored only in HDFS.\n",
    "\n",
    "only for Batch processing -- Batch processing as well as real time processing.\n",
    "\n",
    "Slower than spark because of its I/O latenct -- 100x faster in-memory and 10x faster on disk.\n",
    "\n",
    "Data processing enginer -- Data analytics enginer\n",
    "\n",
    "Supports SQL through HiveSQL -- Supports SQL through spark SQL\n",
    "\n",
    "MapReduce is not interactive -- Spark is interactive\n",
    "\n",
    "More lines of code -- Less lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-Memory Computing:** Keeping data in server's RAM as it makes is easy to access data and makes Machine learning algorithms to work faster.\n",
    "\n",
    "**Lazy Evaluation** Execution will not start until action is triggered.\n",
    "\n",
    "**Supports multiple Languages:** Spark allows you to write applications on Java, Python, Scala and R.\n",
    "\n",
    "**100x faster**\n",
    "\n",
    "**Advanced Analytics:** Spark not only supports 'Map' and 'Reduce' it also supports SQL queries, Streaming data, Machine Learning Algorithms, and Graph algorithms.\n",
    "\n",
    "**Real-Time Processing** Spark can handle real-time processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation vs Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two types of operations in spark are Transformation and Action.\n",
    "\n",
    "Transformation is a function that produces new RDD from existing RDD but when we want to work with existing dataset at that point action is performed.\n",
    "\n",
    "• map(), filter(), union()  ---> Transformations\n",
    "\n",
    "• reduce(), collect(), count() ---> Actions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark Dataframes are standard way of using spark Machine Learning Capabilities.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 methods to deploy spark engine\n",
    "\n",
    "1. ubuntu + spark + python in virtualbox\n",
    "\n",
    "2. Amazon EC2 with Python and Spark\n",
    "\n",
    "3. Databricks notebook System\n",
    "\n",
    "4. AWS EMR Notebook (not free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC2 (Elastic Cloud Compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
